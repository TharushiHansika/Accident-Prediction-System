{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5317,"status":"ok","timestamp":1738671627407,"user":{"displayName":"Research waanigasinghe","userId":"05363278935863643152"},"user_tz":-330},"id":"dcbqhwIYNCri","outputId":"5850e927-86cb-447c-fafe-00c60ca76563"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","# Step 1: Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1fO4kSAEKcnWfRoN8N5ZhSt_EDU6IYLZW"},"id":"9w9eOPzFKMQp","outputId":"9fd4734c-0ec3-49fb-bb56-ee59ffaaa0a4"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Define dataset paths\n","dataset_root = \"/content/drive/MyDrive/TharuWorks/Dataset/train\"  # Adjust path if necessary\n","images_dir = os.path.join(dataset_root, \"images\")  # RGB images\n","tracked_labels_dir = os.path.join(dataset_root, \"tracked_labels\")  # Tracked labels\n","tracked_images_dir = os.path.join(dataset_root, \"tracked_images\")  # Save visualization\n","os.makedirs(tracked_images_dir, exist_ok=True)\n","\n","# Step 1: Process all tracked frames sequentially\n","prev_tracked_objects = {}\n","\n","for label_file in sorted(os.listdir(tracked_labels_dir)):\n","    if not label_file.endswith(\".txt\"):\n","        continue\n","\n","    # Derive corresponding image filename\n","    image_filename = label_file.replace(\".txt\", \".jpg\")\n","    image_path = os.path.join(images_dir, image_filename)\n","    label_path = os.path.join(tracked_labels_dir, label_file)\n","\n","    # Check if files exist before proceeding\n","    if not os.path.exists(image_path) or not os.path.exists(label_path):\n","        print(f\"⚠️ Missing file for {label_file}, skipping...\")\n","        continue\n","\n","    # Load the RGB image\n","    image = cv2.imread(image_path)\n","\n","    if image is None:\n","        print(f\"❌ Error loading RGB image: {image_filename}\")\n","        continue\n","\n","    # Read tracked label file\n","    with open(label_path, \"r\") as f:\n","        lines = f.readlines()\n","\n","    img_height, img_width, _ = image.shape\n","    current_tracked_objects = {}\n","\n","    # **Step 2: Process Each Bounding Box**\n","    for line in lines:\n","        parts = line.strip().split()\n","\n","        # Ignore \"closest\" keyword by keeping only the first six numerical values\n","        parts = parts[:6]\n","\n","        # Validate line contains exactly six values (class_id, x, y, width, height, depth)\n","        if len(parts) != 6:\n","            print(f\"⚠️ Invalid line in {label_file}: {line.strip()} (Skipping)\")\n","            continue  # Skip invalid entries\n","\n","        try:\n","            class_id, x_center, y_center, width, height, depth = map(float, parts)\n","        except ValueError:\n","            print(f\"⚠️ Non-numeric value found in {label_file}: {line.strip()} (Skipping)\")\n","            continue  # Skip entries with incorrect format\n","\n","        # Convert YOLO format (normalized) to pixel values\n","        x_min = int((x_center - width / 2) * img_width)\n","        y_min = int((y_center - height / 2) * img_height)\n","        x_max = int((x_center + width / 2) * img_width)\n","        y_max = int((y_center + height / 2) * img_height)\n","\n","        # Ensure bounding box is within valid bounds\n","        x_min, y_min = max(0, x_min), max(0, y_min)\n","        x_max, y_max = min(img_width - 1, x_max), min(img_height - 1, y_max)\n","\n","        # Store object info\n","        current_tracked_objects[(x_min, y_min, x_max, y_max, class_id)] = depth\n","\n","    # **Step 3: Highlight Tracked Objects**\n","    for obj, depth in current_tracked_objects.items():\n","        x_min, y_min, x_max, y_max, class_id = obj\n","\n","        # Assign different colors for pedestrians and vehicles\n","        color = (0, 255, 0)  # Default: Green\n","        if int(class_id) == 22:  # Vehicle\n","            color = (255, 0, 0)  # Red\n","        elif int(class_id) == 11:  # Pedestrian\n","            color = (0, 0, 255)  # Blue\n","\n","        # **Draw Rectangle Around the Object**\n","        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 2)\n","\n","        # **Add Depth Text**\n","        text = f\"Depth: {depth:.2f}m\"\n","        cv2.putText(image, text, (x_min, y_min - 5),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","\n","    # **Step 4: Save and Display the Annotated Image**\n","    annotated_image_path = os.path.join(tracked_images_dir, image_filename)\n","    cv2.imwrite(annotated_image_path, image)\n","    print(f\"✅ Tracked image saved: {annotated_image_path}\")\n","\n","    # Show the image with bounding boxes\n","    plt.figure(figsize=(10, 6))\n","    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for Matplotlib\n","    plt.title(f\"Tracked Objects on {image_filename}\")\n","    plt.axis(\"off\")\n","    plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPAVUN5dmmdK7OABZRSIAb8","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}